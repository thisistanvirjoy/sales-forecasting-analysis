{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ee86920-4ab4-4280-bda2-b3cd048d7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ UnicodeDecodeError: UTF-8 failed. Trying 'latin-1' encoding...\n",
      "✅ Dataset loaded successfully with latin-1 encoding!\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
      "2       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
      "3       6  CA-2014-115812    6/9/2014   6/14/2014  Standard Class    BH-11710   \n",
      "4      11  CA-2014-115812    6/9/2014   6/14/2014  Standard Class    BH-11710   \n",
      "\n",
      "     Customer Name   Segment        Country             City  ... Postal Code  \\\n",
      "0      Claire Gute  Consumer  United States        Henderson  ...       42420   \n",
      "1      Claire Gute  Consumer  United States        Henderson  ...       42420   \n",
      "2   Sean O'Donnell  Consumer  United States  Fort Lauderdale  ...       33311   \n",
      "3  Brosina Hoffman  Consumer  United States      Los Angeles  ...       90032   \n",
      "4  Brosina Hoffman  Consumer  United States      Los Angeles  ...       90032   \n",
      "\n",
      "   Region       Product ID   Category Sub-Category  \\\n",
      "0   South  FUR-BO-10001798  Furniture    Bookcases   \n",
      "1   South  FUR-CH-10000454  Furniture       Chairs   \n",
      "2   South  FUR-TA-10000577  Furniture       Tables   \n",
      "3    West  FUR-FU-10001487  Furniture  Furnishings   \n",
      "4    West  FUR-TA-10001539  Furniture       Tables   \n",
      "\n",
      "                                        Product Name      Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase   261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...   731.9400         3   \n",
      "2      Bretford CR4500 Series Slim Rectangular Table   957.5775         5   \n",
      "3  Eldon Expressions Wood and Plastic Desk Access...    48.8600         7   \n",
      "4           Chromcraft Rectangular Conference Tables  1706.1840         9   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.45 -383.0310  \n",
      "3      0.00   14.1694  \n",
      "4      0.20   85.3092  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2121 entries, 0 to 2120\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Row ID         2121 non-null   int64  \n",
      " 1   Order ID       2121 non-null   object \n",
      " 2   Order Date     2121 non-null   object \n",
      " 3   Ship Date      2121 non-null   object \n",
      " 4   Ship Mode      2121 non-null   object \n",
      " 5   Customer ID    2121 non-null   object \n",
      " 6   Customer Name  2121 non-null   object \n",
      " 7   Segment        2121 non-null   object \n",
      " 8   Country        2121 non-null   object \n",
      " 9   City           2121 non-null   object \n",
      " 10  State          2121 non-null   object \n",
      " 11  Postal Code    2121 non-null   int64  \n",
      " 12  Region         2121 non-null   object \n",
      " 13  Product ID     2121 non-null   object \n",
      " 14  Category       2121 non-null   object \n",
      " 15  Sub-Category   2121 non-null   object \n",
      " 16  Product Name   2121 non-null   object \n",
      " 17  Sales          2121 non-null   float64\n",
      " 18  Quantity       2121 non-null   int64  \n",
      " 19  Discount       2121 non-null   float64\n",
      " 20  Profit         2121 non-null   float64\n",
      "dtypes: float64(3), int64(3), object(15)\n",
      "memory usage: 348.1+ KB\n",
      "\n",
      "Descriptive Statistics:\n",
      "            Row ID   Postal Code        Sales     Quantity     Discount  \\\n",
      "count  2121.000000   2121.000000  2121.000000  2121.000000  2121.000000   \n",
      "mean   5041.643564  55726.556341   349.834887     3.785007     0.173923   \n",
      "std    2885.740258  32261.888225   503.179145     2.251620     0.181547   \n",
      "min       1.000000   1040.000000     1.892000     1.000000     0.000000   \n",
      "25%    2568.000000  22801.000000    47.040000     2.000000     0.000000   \n",
      "50%    5145.000000  60505.000000   182.220000     3.000000     0.200000   \n",
      "75%    7534.000000  90032.000000   435.168000     5.000000     0.300000   \n",
      "max    9991.000000  99301.000000  4416.174000    14.000000     0.700000   \n",
      "\n",
      "            Profit  \n",
      "count  2121.000000  \n",
      "mean      8.699327  \n",
      "std     136.049246  \n",
      "min   -1862.312400  \n",
      "25%     -12.849000  \n",
      "50%       7.774800  \n",
      "75%      33.726600  \n",
      "max    1013.127000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path to your downloaded CSV file.\n",
    "# Make sure the path is correct for your system.\n",
    "file_path = 'C:/Users/USER/data analysis projects/stores_sales_forecasting.csv'\n",
    "\n",
    "# Try loading the dataset with common encodings\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    print(\"✅ Dataset loaded successfully with utf-8 encoding!\")\n",
    "except UnicodeDecodeError:\n",
    "    print(\"❌ UnicodeDecodeError: UTF-8 failed. Trying 'latin-1' encoding...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='latin-1') # Often works for these errors\n",
    "        print(\"✅ Dataset loaded successfully with latin-1 encoding!\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"❌ UnicodeDecodeError: Latin-1 failed. Trying 'ISO-8859-1' encoding...\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='ISO-8859-1') # Also very common\n",
    "            print(\"✅ Dataset loaded successfully with ISO-8859-1 encoding!\")\n",
    "        except UnicodeDecodeError:\n",
    "            print(\"❌ UnicodeDecodeError: ISO-8859-1 failed. Trying 'cp1252' encoding...\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='cp1252') # Another common Windows encoding\n",
    "                print(\"✅ Dataset loaded successfully with cp1252 encoding!\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error: Could not decode the file with common encodings. Original error: {e}\")\n",
    "                exit()\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at {file_path}. Please double-check the 'file_path' variable.\")\n",
    "    exit()\n",
    "except Exception as e: # Catch any other unexpected errors during initial load\n",
    "    print(f\"❌ An unexpected error occurred during file loading: {e}\")\n",
    "    exit()\n",
    "\n",
    "# If the file loaded successfully, print the first 5 rows and info to confirm\n",
    "if 'df' in locals(): # Check if df variable exists after successful load\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nDataset Information:\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c2cd6-6498-4cfa-bbe1-3d388aa91f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define the file path to your NEW downloaded CSV file (e.g., 'US Superstore Data.csv').\n",
    "# Make sure the path is correct for your system.\n",
    "# IMPORTANT: Replace 'train.csv' with the correct filename for the dataset you download\n",
    "# that *includes* the 'Profit' column.\n",
    "file_path = 'C:/Users/USER/data analysis projects/US Superstore Data.csv' # <--- CHANGE THIS FILENAME\n",
    "\n",
    "# Load the dataset into a pandas DataFrame.\n",
    "try:\n",
    "    df = pd.read_csv(file_path, encoding='ISO-8859-1') # Often, Superstore data uses this encoding\n",
    "    print(\"✅ Dataset loaded successfully!\")\n",
    "    print(\"\\nFirst 5 rows of the dataset after loading the correct file:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDataset Information after loading the correct file:\")\n",
    "    df.info()\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: File not found at {file_path}. Please double-check the 'file_path' variable and ensure you've downloaded the correct dataset with a 'Profit' column.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Starting EDA phase...\")\n",
    "\n",
    "# --- Data Cleaning & Wrangling (revisiting based on df.info() and df.describe()) ---\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing 'Postal Code' values. Median is a reasonable choice for numerical data.\n",
    "# This ensures operations like geographical analysis don't break.\n",
    "# The 'US Superstore Data.csv' often has missing 'Postal Code' in some non-US rows.\n",
    "if 'Postal Code' in df.columns and df['Postal Code'].isnull().any():\n",
    "    df['Postal Code'].fillna(df['Postal Code'].median(), inplace=True)\n",
    "    print(\"\\nFilled missing 'Postal Code' values with the median.\")\n",
    "# Convert Postal Code to int if it's float and has no NaNs now\n",
    "if 'Postal Code' in df.columns and df['Postal Code'].dtype == 'float64' and df['Postal Code'].isnull().sum() == 0:\n",
    "    df['Postal Code'] = df['Postal Code'].astype(int)\n",
    "\n",
    "\n",
    "# Correcting Data Types for 'Order Date' and 'Ship Date'\n",
    "# Common formats are 'DD/MM/YYYY' or 'MM/DD/YYYY'.\n",
    "# The 'US Superstore Data.csv' often uses 'MM/DD/YYYY' so `infer_datetime_format=True` or `format='%m/%d/%Y'` works well.\n",
    "# Let's try `infer_datetime_format=True` first, it's often robust.\n",
    "# If that fails, go back to `dayfirst=True` or explicit `format`.\n",
    "try:\n",
    "    df['Order Date'] = pd.to_datetime(df['Order Date'], infer_datetime_format=True)\n",
    "    df['Ship Date'] = pd.to_datetime(df['Ship Date'], infer_datetime_format=True)\n",
    "except Exception as e:\n",
    "    print(f\"Could not infer date format, trying with dayfirst=True. Error: {e}\")\n",
    "    try:\n",
    "        df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True)\n",
    "        df['Ship Date'] = pd.to_datetime(df['Ship Date'], dayfirst=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not convert dates even with dayfirst=True. Please inspect date format. Error: {e}\")\n",
    "        # Fallback for specific known formats if the above fails\n",
    "        # df['Order Date'] = pd.to_datetime(df['Order Date'], format='%d/%m/%Y')\n",
    "        # df['Ship Date'] = pd.to_datetime(df['Ship Date'], format='%d/%m/%Y')\n",
    "\n",
    "\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.info())\n",
    "\n",
    "# Feature Engineering (creating new features from existing ones)\n",
    "# Extract Year, Month, Day from Order Date for time-series analysis\n",
    "df['Order Year'] = df['Order Date'].dt.year\n",
    "df['Order Month'] = df['Order Date'].dt.month\n",
    "df['Order Day'] = df['Order Date'].dt.day\n",
    "df['Order DayOfWeek'] = df['Order Date'].dt.dayofweek # Monday=0, Sunday=6\n",
    "df['Order WeekOfYear'] = df['Order Date'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# Calculate 'Days to Ship'\n",
    "df['DaysToShip'] = (df['Ship Date'] - df['Order Date']).dt.days\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nNumber of duplicate rows: {df.duplicated().sum()}\")\n",
    "if df.duplicated().sum() > 0:\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicate rows removed.\")\n",
    "\n",
    "# --- NOW, THE REST OF THE EDA VISUALIZATIONS WILL WORK AS 'Profit' COLUMN SHOULD BE PRESENT ---\n",
    "\n",
    "# 1. Sales and Profit Distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['Sales'], bins=50, kde=True)\n",
    "plt.title('Distribution of Sales')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log') # Sales often have a long tail, log scale helps visualize\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Profit'], bins=50, kde=True) # This line will now work\n",
    "plt.title('Distribution of Profit')\n",
    "plt.xlabel('Profit')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observe: Sales and Profit distributions are often skewed. Many small transactions, few large.\n",
    "# Negative profits indicate losses.\n",
    "\n",
    "# 2. Relationship between Sales and Profit\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Sales', y='Profit', data=df, alpha=0.6)\n",
    "plt.title('Sales vs. Profit')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Profit')\n",
    "plt.xscale('log') # Log scale helps spread out points for better visibility\n",
    "plt.show()\n",
    "\n",
    "# Observe: General positive correlation, but many points with high sales and low/negative profit.\n",
    "# This indicates products with high sales but poor profitability.\n",
    "\n",
    "# 3. Profit Ratio\n",
    "# Ensure Sales is not zero to avoid division by zero\n",
    "df['Profit Ratio'] = (df['Profit'] / df['Sales']) * 100\n",
    "# Handle division by zero if Sales is 0, setting Profit Ratio to 0 in such cases\n",
    "df.loc[df['Sales'] == 0, 'Profit Ratio'] = 0\n",
    "# Replace infinite values (if Sales was 0 and Profit was non-zero) with 0\n",
    "df['Profit Ratio'].replace([float('inf'), -float('inf')], 0, inplace=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Profit Ratio'], bins=50, kde=True)\n",
    "plt.title('Distribution of Profit Ratio (%)')\n",
    "plt.xlabel('Profit Ratio (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Observe: What's the typical profit margin? Are there many loss-making items?\n",
    "\n",
    "# 4. Sales and Profit by Category and Sub-Category\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "# Sales by Category\n",
    "sales_by_category = df.groupby('Category')['Sales'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=sales_by_category.index, y=sales_by_category.values, ax=axes[0], palette='viridis')\n",
    "axes[0].set_title('Total Sales by Category')\n",
    "axes[0].set_xlabel('Category')\n",
    "axes[0].set_ylabel('Total Sales')\n",
    "axes[0].ticklabel_format(style='plain', axis='y') # Prevent scientific notation\n",
    "\n",
    "# Profit by Category\n",
    "profit_by_category = df.groupby('Category')['Profit'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=profit_by_category.index, y=profit_by_category.values, ax=axes[1], palette='magma')\n",
    "axes[1].set_title('Total Profit by Category')\n",
    "axes[1].set_xlabel('Category')\n",
    "axes[1].set_ylabel('Total Profit')\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observe: Which categories are top performers in sales and profit? Are they consistent?\n",
    "\n",
    "# Sales and Profit by Sub-Category (Top N)\n",
    "plt.figure(figsize=(14, 8))\n",
    "top_subcategories_sales = df.groupby('Sub-Category')['Sales'].sum().nlargest(15).index\n",
    "sns.barplot(x='Sales', y='Sub-Category', data=df[df['Sub-Category'].isin(top_subcategories_sales)],\n",
    "            estimator=sum, palette='viridis', ci=None, order=top_subcategories_sales)\n",
    "plt.title('Top 15 Sub-Categories by Total Sales')\n",
    "plt.xlabel('Total Sales')\n",
    "plt.ylabel('Sub-Category')\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "top_subcategories_profit = df.groupby('Sub-Category')['Profit'].sum().nlargest(15).index\n",
    "sns.barplot(x='Profit', y='Sub-Category', data=df[df['Sub-Category'].isin(top_subcategories_profit)],\n",
    "            estimator=sum, palette='magma', ci=None, order=top_subcategories_profit)\n",
    "plt.title('Top 15 Sub-Categories by Total Profit')\n",
    "plt.xlabel('Total Profit')\n",
    "plt.ylabel('Sub-Category')\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.show()\n",
    "\n",
    "# Identify loss-making sub-categories\n",
    "loss_making_subcategories = df.groupby('Sub-Category')['Profit'].sum().sort_values(ascending=True)\n",
    "print(\"\\nSub-Categories with Negative Profit:\")\n",
    "print(loss_making_subcategories[loss_making_subcategories < 0])\n",
    "\n",
    "# Observe: Are the top sales sub-categories also the top profit sub-categories?\n",
    "# Which sub-categories are consistently losing money? This is crucial for inventory/marketing.\n",
    "\n",
    "# 5. Sales and Profit by Region/State/City\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 16))\n",
    "\n",
    "# Sales by Region\n",
    "sales_by_region = df.groupby('Region')['Sales'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=sales_by_region.index, y=sales_by_region.values, ax=axes[0], palette='crest')\n",
    "axes[0].set_title('Total Sales by Region')\n",
    "axes[0].set_xlabel('Region')\n",
    "axes[0].set_ylabel('Total Sales')\n",
    "axes[0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# Profit by Region\n",
    "profit_by_region = df.groupby('Region')['Profit'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=profit_by_region.index, y=profit_by_region.values, ax=axes[1], palette='flare')\n",
    "axes[1].set_title('Total Profit by Region')\n",
    "axes[1].set_xlabel('Region')\n",
    "axes[1].set_ylabel('Total Profit')\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observe: Are there regional disparities in sales and profit? This helps target marketing.\n",
    "\n",
    "# 6. Sales and Profit by Customer Segment\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12))\n",
    "\n",
    "# Sales by Segment\n",
    "sales_by_segment = df.groupby('Segment')['Sales'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=sales_by_segment.index, y=sales_by_segment.values, ax=axes[0], palette='cubehelix')\n",
    "axes[0].set_title('Total Sales by Customer Segment')\n",
    "axes[0].set_xlabel('Segment')\n",
    "axes[0].set_ylabel('Total Sales')\n",
    "axes[0].ticklabel_format(style='plain', axis='y')\n",
    "\n",
    "# Profit by Segment\n",
    "profit_by_segment = df.groupby('Segment')['Profit'].sum().sort_values(ascending=False)\n",
    "sns.barplot(x=profit_by_segment.index, y=profit_by_segment.values, ax=axes[1], palette='rocket')\n",
    "axes[1].set_title('Total Profit by Customer Segment')\n",
    "axes[1].set_xlabel('Segment')\n",
    "axes[1].set_ylabel('Total Profit')\n",
    "axes[1].ticklabel_format(style='plain', axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observe: Which segments are most profitable? How do sales and profit differ across segments?\n",
    "\n",
    "# 7. Time-Series Analysis: Sales and Profit Over Time\n",
    "# Resample data to monthly frequency\n",
    "monthly_sales_profit = df.set_index('Order Date')[['Sales', 'Profit']].resample('M').sum()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_sales_profit.index, monthly_sales_profit['Sales'], label='Monthly Sales', marker='o', markersize=4)\n",
    "plt.plot(monthly_sales_profit.index, monthly_sales_profit['Profit'], label='Monthly Profit', marker='x', markersize=4)\n",
    "plt.title('Monthly Sales and Profit Trends Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Amount')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Observe: Identify overall trends (growth/decline), seasonality (e.g., end-of-year spikes),\n",
    "# and any unusual dips or peaks.\n",
    "\n",
    "# Sales and Profit by Year\n",
    "yearly_sales_profit = df.groupby('Order Year')[['Sales', 'Profit']].sum()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "yearly_sales_profit.plot(kind='bar', y=['Sales', 'Profit'], figsize=(10, 6))\n",
    "plt.title('Yearly Sales and Profit')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Amount')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Sales and Profit by Month (aggregated across all years to see seasonality)\n",
    "monthly_avg_sales_profit = df.groupby('Order Month')[['Sales', 'Profit']].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_avg_sales_profit.plot(kind='bar', y=['Sales', 'Profit'], figsize=(10, 6))\n",
    "plt.title('Average Monthly Sales and Profit (Aggregated)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Amount')\n",
    "plt.xticks(ticks=range(12), labels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'], rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.ticklabel_format(style='plain', axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Observe: Clear seasonality? Which months are strongest/weakest?\n",
    "\n",
    "# 8. Quantity, Discount, and their impact on Sales/Profit\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x='Quantity', y='Profit', data=df, alpha=0.6)\n",
    "plt.title('Quantity vs. Profit')\n",
    "plt.xlabel('Quantity')\n",
    "plt.ylabel('Profit')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x='Discount', y='Profit', data=df, alpha=0.6)\n",
    "plt.title('Discount vs. Profit')\n",
    "plt.xlabel('Discount')\n",
    "plt.ylabel('Profit')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observe: Discounts often lead to negative profits. This is a critical insight.\n",
    "\n",
    "# Correlation Matrix for numerical features\n",
    "# Ensure 'Shipping Cost' and 'Discount' are present in the new dataset as well\n",
    "# The US Superstore Data.csv typically has these.\n",
    "numerical_cols = ['Sales', 'Quantity', 'Discount', 'Profit', 'Shipping Cost', 'Profit Ratio', 'DaysToShip']\n",
    "# Filter out columns that might not exist in the specific loaded dataset (e.g., if 'Shipping Cost' was missing)\n",
    "actual_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[actual_numerical_cols].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "print(\"EDA phase completed. Insights have been generated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
